### **[캐글](https://www.kaggle.com/)을 통한 머신러닝 공부** 
D
* Decision Tree / 의사결정트리 ([2.1](https://github.com/yongukpark/Data-Science/blob/c2e8830f0fd6d1562b08aee0cba61295a8d07d77/2.Intro%20to%20Machine%20Learning/1-1.How%20Models%20Work/How%20Models%20Work.ipynb))  

M
* MAE ([2.4](https://github.com/yongukpark/Data-Science/blob/f63b74531e081dc38da7278ac082cbc8c649e824/2.Intro%20to%20Machine%20Learning/4-1.Model%20Validation/Model%20Validation.ipynb))   

N
* ndarray ([1.2](https://github.com/yongukpark/Data-Science/blob/f63b74531e081dc38da7278ac082cbc8c649e824/1.python/2-1.module/module.ipynb))  

O
* overfitting ([2.5](https://github.com/yongukpark/Data-Science/blob/f63b74531e081dc38da7278ac082cbc8c649e824/2.Intro%20to%20Machine%20Learning/5-1.Underfitting%20and%20Overfitting/Underfitting%20and%20Overfitting.ipynb))  

R
* random forest / 랜덤포레스트 ([1.3](https://github.com/yongukpark/Data-Science/blob/f63b74531e081dc38da7278ac082cbc8c649e824/1.python/3.Titanic/Titanic.ipynb), [2.6](https://github.com/yongukpark/Data-Science/blob/f63b74531e081dc38da7278ac082cbc8c649e824/2.Intro%20to%20Machine%20Learning/6-1.Random%20Forests/Random%20Forests.ipynb))  

U
* underfitting ([2.5](https://github.com/yongukpark/Data-Science/blob/f63b74531e081dc38da7278ac082cbc8c649e824/2.Intro%20to%20Machine%20Learning/5-1.Underfitting%20and%20Overfitting/Underfitting%20and%20Overfitting.ipynb))  
